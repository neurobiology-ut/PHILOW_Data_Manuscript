{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29236\\4210486049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input , concatenate , Conv2D , MaxPooling2D , Activation , UpSampling2D , BatchNormalization, Conv2DTranspose, Add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true , y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true , y_pred):\n",
    "    loss = 1- dice_coeff(y_true , y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true , y_pred):\n",
    "    loss = binary_crossentropy(y_true , y_pred) + dice_loss(y_true , y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_uint(input_tensor, nb_filter):\n",
    "    \n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_nest_unet_512_layer_5(input_shape=(512, 512, 1), num_classes=3, deep_supervision = False):\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        \n",
    "        inputs = Input(shape = input_shape)\n",
    "        \n",
    "        # 512\n",
    "        conv1_1 = standard_uint(inputs, nb_filter = 16)\n",
    "        pool1 = MaxPooling2D((2, 2), strides = (2, 2))(conv1_1)\n",
    "        \n",
    "        #256\n",
    "        conv2_1 = standard_uint(pool1, nb_filter = 32)\n",
    "        pool2 = MaxPooling2D((2, 2), strides = (2, 2))(conv2_1)\n",
    "        \n",
    "        up1_2 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], axis = 3)\n",
    "        conv1_2 = standard_uint(conv1_2, nb_filter = 16)\n",
    "        \n",
    "        #128\n",
    "        conv3_1 = standard_uint(pool2, nb_filter = 64)\n",
    "        pool3 = MaxPooling2D((2, 2), strides = (2, 2))(conv3_1)\n",
    "        \n",
    "        up2_2 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], axis = 3)\n",
    "        conv2_2 = standard_uint(conv2_2, nb_filter = 32)\n",
    "        \n",
    "        up1_3 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], axis = 3)\n",
    "        conv1_3 = standard_uint(conv1_3, nb_filter = 16)\n",
    "        \n",
    "        # 64\n",
    "        conv4_1 = standard_uint(pool3, nb_filter = 128)\n",
    "        pool4 = MaxPooling2D((2, 2), strides = (2, 2))(conv4_1)      \n",
    "        \n",
    "        up3_2 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], axis = 3)\n",
    "        conv3_2 = standard_uint(conv3_2, nb_filter = 64)    \n",
    "        \n",
    "        up2_3 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], axis = 3)\n",
    "        conv2_3 = standard_uint(conv2_3, nb_filter = 32)        \n",
    "        \n",
    "        up1_4 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_2, conv1_3], axis = 3)\n",
    "        conv1_4 = standard_uint(conv1_4, nb_filter = 16)       \n",
    "        \n",
    "        # 32\n",
    "        conv5_1 = standard_uint(pool4, nb_filter = 256)    \n",
    "        \n",
    "        up4_2 = Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], axis = 3)\n",
    "        conv4_2 = standard_uint(conv4_2, nb_filter = 128)  \n",
    "        \n",
    "        up3_3 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], axis = 3)\n",
    "        conv3_3 = standard_uint(conv3_3, nb_filter = 64)\n",
    "        \n",
    "        up2_4 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], axis = 3)\n",
    "        conv2_4 = standard_uint(conv2_4, nb_filter = 32)\n",
    "        \n",
    "        up1_5 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], axis = 3)\n",
    "        conv1_5 = standard_uint(conv1_5, nb_filter = 16)\n",
    "        \n",
    "        \n",
    "        \n",
    "        nested_output_1 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_2)\n",
    "        nested_output_2 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_3)\n",
    "        nested_output_3 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_4)\n",
    "        nested_output_4 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_5)\n",
    "        \n",
    "        if deep_supervision:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_1, nested_output_2, nested_output_3, nested_output_4]) \n",
    "        else:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_4])\n",
    "            \n",
    "        model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(image):\n",
    "    return image / 127.5 - 1\n",
    "\n",
    "def normalize_y(image):\n",
    "    return image / 255\n",
    "\n",
    "def denormalize_y(image):\n",
    "    return image * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Y_gray_with_gaussian(folder_path, thresh = None , normalize = True, g_size = None):\n",
    "    image_files = []    \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    print(image_files)\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros(\n",
    "        (len(image_files), img.shape[0], img.shape[1], 1) ,np.float32\n",
    "    )\n",
    "    \n",
    "    for i , image_file in enumerate(image_files):\n",
    "        image = cv2.imread(\n",
    "            folder_path + os.sep + image_file ,\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "\n",
    "        if g_size:\n",
    "            image = cv2.GaussianBlur(\n",
    "                image, (g_size, g_size), 0\n",
    "            )\n",
    "                \n",
    "        if thresh:\n",
    "            ret , image = cv2.threshold(image , thresh , 255 , cv2.THRESH_BINARY)\n",
    "        image = image[ : , : , np.newaxis]\n",
    "        if normalize:\n",
    "            images[i] = normalize_y(image)\n",
    "        else:\n",
    "            images[i] = image\n",
    "            \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images , image_files\n",
    "\n",
    "def load_X_gray(folder_path):\n",
    "    \n",
    "    image_files = []       \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    print (image_files)\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1), np.float32)\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        images[i] = normalize_x(image)\n",
    "    return images, image_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_gray_imgs(images):\n",
    "    \n",
    "    H = -(-images.shape[1]//412)\n",
    "    W = -(-images.shape[2]//412)\n",
    "    \n",
    "    diveded_imgs = np.zeros(( images.shape[0]*H*W, 512, 512, 1), np.float32)\n",
    "    print(H,W)\n",
    "    \n",
    "    for z in range(images.shape[0]):\n",
    "        image = images[z]\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                cropped_img = np.zeros((512, 512, 1), np.float32)\n",
    "                cropped_img -= 1\n",
    "                \n",
    "                if images.shape[1] < 412:\n",
    "                    h = -1\n",
    "                if images.shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:images.shape[2]+50, 0] = image[0:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:512, 0] = image[0:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:images.shape[1]+50, 0:images.shape[2]-412*W-50, 0] = image[0:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        cropped_img[50:images.shape[1]+50, :, 0] = image[0:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:512, 50:images.shape[2]+50, 0] = image[0:462, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:512, 50:512, 0] = image[0:462, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:512, 0:images.shape[2]-412*W-50, 0] = image[0:462, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[50:512, 0:images.shape[2]-412*(W-1)-50, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:images.shape[2]+50, 0] = image[h*412-50:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:512, 0] = image[h*412-50:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, :, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                        cropped_img[:, 50:images.shape[2]+50, 0] = image[h*412-50:(h+1)*412+50, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        try:\n",
    "                            cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        try:\n",
    "                            cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]         \n",
    "                        except:\n",
    "                            try:\n",
    "                                 cropped_img[:, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                            except:\n",
    "                                 cropped_img[0:images.shape[1]-412*(H-1)-50, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                h = max(0, h)\n",
    "                w = max(0, w)\n",
    "                diveded_imgs[z*H*W+ w*H+h] = cropped_img\n",
    "                \n",
    "    return diveded_imgs\n",
    "\n",
    "\n",
    "def merge_imgs(imgs, original_image_shape):\n",
    "    \n",
    "    merged_imgs = np.zeros((original_image_shape[0], original_image_shape[1], original_image_shape[2], 1), np.float32)\n",
    "    H = -(-original_image_shape[1]//412)\n",
    "    W = -(-original_image_shape[2]//412)    \n",
    "    \n",
    "    for z in range(original_image_shape[0]):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "\n",
    "                if original_image_shape[1] < 412:\n",
    "                    h = -1\n",
    "                if original_image_shape[2] < 412:\n",
    "                    w = -1\n",
    " \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:(h+1)*412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]  \n",
    "                        \n",
    "    return merged_imgs\n",
    "\n",
    "\n",
    "\n",
    "def divide_imgs(images):\n",
    "    \n",
    "    H = -(-images.shape[1]//412)\n",
    "    W = -(-images.shape[2]//412)\n",
    "    \n",
    "    diveded_imgs = np.zeros(( images.shape[0]*H*W, 512, 512, 1), np.float32)\n",
    "    print(H,W)\n",
    "    \n",
    "    for z in range(images.shape[0]):\n",
    "        image = images[z]\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                cropped_img = np.zeros((512, 512, 1), np.float32)\n",
    "                cropped_img -= 1\n",
    "                \n",
    "                if images.shape[1] < 412:\n",
    "                    h = -1\n",
    "                if images.shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:images.shape[2]+50, 0] = image[0:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:512, 0] = image[0:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:images.shape[1]+50, 0:images.shape[2]-412*W-50, 0] = image[0:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        cropped_img[50:images.shape[1]+50, :, 0] = image[0:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:512, 50:images.shape[2]+50, 0] = image[0:462, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:512, 50:512, 0] = image[0:462, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:512, 0:images.shape[2]-412*W-50, 0] = image[0:462, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[50:512, 0:images.shape[2]-412*(W-1)-50, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:images.shape[2]+50, 0] = image[h*412-50:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:512, 0] = image[h*412-50:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, :, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                        cropped_img[:, 50:images.shape[2]+50, 0] = image[h*412-50:(h+1)*412+50, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        try:\n",
    "                            cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        try:\n",
    "                            cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]         \n",
    "                        except:\n",
    "                            try:\n",
    "                                 cropped_img[:, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                            except:\n",
    "                                 cropped_img[0:images.shape[1]-412*(H-1)-50, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                h = max(0, h)\n",
    "                w = max(0, w)\n",
    "                diveded_imgs[z*H*W+ w*H+h] = cropped_img\n",
    "                \n",
    "    return diveded_imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_datasets(ori_images, label_images, num_list):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args : \n",
    "            ori_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            label_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            num_list (list) : num\n",
    "            \n",
    "        Returns : \n",
    "            train_ori_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            train_label_images (numpy.ndarray) : Z, Y, X, 1\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    train_ori_images = list()\n",
    "    train_label_images = list()\n",
    "    for num in num_list:\n",
    "        ori_image = ori_images[num]\n",
    "        label_image = label_images[num]\n",
    "\n",
    "        x_range = [int(ori_image.shape[0] * 0.1), int(ori_image.shape[0] * 0.9)]\n",
    "        y_range = [int(ori_image.shape[1] * 0.1), int(ori_image.shape[1] * 0.9)]\n",
    "        \n",
    "        train_ori_images.append(ori_image[x_range[0]:x_range[1], y_range[0]:y_range[1], :])\n",
    "        train_label_images.append(label_image[x_range[0]:x_range[1], y_range[0]:y_range[1], :])\n",
    "        \n",
    "    cropped_ori_images = divide_gray_imgs(np.array(train_ori_images))\n",
    "    cropped_label_images = divide_gray_imgs(np.array(train_label_images))\n",
    "    \n",
    "    cropped_label_images = np.where(\n",
    "        cropped_label_images == -1,\n",
    "        0,\n",
    "        cropped_label_images\n",
    "    )\n",
    "        \n",
    "    return cropped_ori_images, cropped_label_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(X_train,Y_train, csv_path, model_path ,input_shape=(512, 512, 1), num_classes=1):\n",
    "    Y_train = Y_train\n",
    "    X_train = X_train\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=90.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 1\n",
    "    image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    mask_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_train, seed=seed, batch_size=8)\n",
    "    mask_generator = mask_datagen.flow(Y_train, seed=seed, batch_size=8)\n",
    "\n",
    "    train_generator = (pair for pair in zip(image_generator, mask_generator))\n",
    "    model = get_nest_unet_512_layer_5(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCH = 400\n",
    "    \n",
    "    callbacks = []\n",
    "    from tensorflow.keras.callbacks import CSVLogger\n",
    "    callbacks.append(CSVLogger(csv_path))\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=32, epochs=NUM_EPOCH, verbose=1, callbacks=callbacks)\n",
    "    model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model_path, filenames, out_dir, input_shape=(512, 512, 1), num_classes=1):\n",
    "    \n",
    "    model = get_nest_unet_512_layer_5(input_shape=input_shape, num_classes=num_classes)\n",
    "    \n",
    "    model.load_weights(model_path)\n",
    "    BATCH_SIZE = 1\n",
    "    Y_pred = model.predict(X_test, BATCH_SIZE)\n",
    "    \n",
    "    print(Y_pred.shape)\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "    \n",
    "    if Y_pred.shape[3]!=1:\n",
    "        num = Y_pred.shape[3]\n",
    "        for n in range(num):\n",
    "            os.makedirs(os.path.join(out_dir,str(n+1)), exist_ok=True)\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            for n in range(num):\n",
    "                os.makedirs(os.path.join(out_dir,str(n+1)), exist_ok=True)\n",
    "                cv2.imwrite(os.path.join(out_dir, str(n+1) , str(i).zfill(4) + '.png'), denormalize_y(y[:,:,n]))\n",
    "        \n",
    "    else:\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            cv2.imwrite(os.path.join(out_dir , str(i).zfill(4) + '.png'), denormalize_y(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/dataset/cropped_002/resize_10x10x10/')\n",
    "label_imgs_001 , _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_001//', normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst_001 = [50, 150, 250]\n",
    "\n",
    "cropped_ori_001_imgs, cropped_label_001_imgs = make_train_datasets(ori_imgs, label_imgs_001, num_lst_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_001.csv'\n",
    "X_train = cropped_ori_001_imgs\n",
    "Y_train = cropped_label_001_imgs\n",
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(X_train,Y_train, csv_path, model_path, input_shape,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1\n",
    "filenames = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(ori_imgs)\n",
    "\n",
    "X_test = seped_xy_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_xy_imgs, X_test\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(ori_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "X_test = seped_yz_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_yz_imgs, X_test\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(ori_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "X_test = seped_zx_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_zx_imgs, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_xy, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_001')\n",
    "merged_mito_imgs_xy = merge_imgs(mito_imgs_xy, ori_image_shape)\n",
    "del mito_imgs_xy\n",
    "\n",
    "mito_imgs_yz, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_001')\n",
    "merged_mito_imgs_yz = merge_imgs(mito_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "del mito_imgs_yz\n",
    "\n",
    "mito_imgs_zx, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_001')\n",
    "merged_mito_imgs_zx = merge_imgs(mito_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "del mito_imgs_zx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_ave = merged_mito_imgs_xy * 255 // 3 + merged_mito_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_mito_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_001'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        mito_imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_002\"\n",
    "os.makedirs(out_dir, exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/dataset/cropped_002/resize_10x10x10/')\n",
    "label_imgs_001 , _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_001//', normalize=False)\n",
    "label_imgs_002, _ = load_Y_gray_with_gaussian(\"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_002/\",normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_80_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002/original//')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst_001 = [50, 150, 250]\n",
    "\n",
    "cropped_ori_001_imgs, cropped_label_001_imgs = make_train_datasets(ori_imgs, label_imgs_001, num_lst_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst_002 = [54, 170, 226]\n",
    "\n",
    "cropped_ori_002_imgs, cropped_label_002_imgs  = make_80_train_datasets(ori_80_imgs,  label_imgs_002, num_lst_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_ori_imgs = np.concatenate([cropped_ori_001_imgs, cropped_ori_002_imgs],  axis=0)\n",
    "cropped_label_imgs = np.concatenate([cropped_label_001_imgs, cropped_label_002_imgs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_002.csv'\n",
    "X_train = cropped_ori_imgs\n",
    "Y_train = cropped_label_imgs\n",
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(X_train,Y_train, csv_path, model_path, input_shape,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1\n",
    "filenames = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(ori_imgs)\n",
    "\n",
    "X_test = seped_xy_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_002/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_xy_imgs, X_test\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(ori_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "X_test = seped_yz_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_002/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_yz_imgs, X_test\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(ori_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "X_test = seped_zx_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_002/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_zx_imgs, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_xy, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_002')\n",
    "merged_mito_imgs_xy = merge_imgs(mito_imgs_xy, ori_image_shape)\n",
    "del mito_imgs_xy\n",
    "\n",
    "mito_imgs_yz, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_002')\n",
    "merged_mito_imgs_yz = merge_imgs(mito_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "del mito_imgs_yz\n",
    "\n",
    "mito_imgs_zx, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_002')\n",
    "merged_mito_imgs_zx = merge_imgs(mito_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "del mito_imgs_zx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_ave = merged_mito_imgs_xy * 255 // 3 + merged_mito_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_mito_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_002'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        mito_imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_003\"\n",
    "os.makedirs(out_dir, exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/dataset/cropped_002/resize_10x10x10/')\n",
    "ori_80_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002/original//')\n",
    "\n",
    "label_imgs_001 , _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_001//', normalize=False)\n",
    "label_imgs_002, _ = load_Y_gray_with_gaussian(\"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_002/\",normalize=False)\n",
    "label_imgs_003,  _ = load_Y_gray_with_gaussian(\"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_003/\",normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst_001 = [50, 150, 250]\n",
    "\n",
    "cropped_ori_001_imgs, cropped_label_001_imgs = make_train_datasets(ori_imgs, label_imgs_001, num_lst_001)\n",
    "\n",
    "num_lst_002 = [54, 170, 226]\n",
    "num_lst_003 = [57, 92, 166, 202]\n",
    "\n",
    "cropped_ori_002_imgs, cropped_label_002_imgs  = make_80_train_datasets(ori_80_imgs,  label_imgs_002, num_lst_002)\n",
    "cropped_ori_003_imgs, cropped_label_003_imgs  = make_80_train_datasets(ori_80_imgs,  label_imgs_003, num_lst_003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_ori_imgs = np.concatenate([cropped_ori_001_imgs, cropped_ori_002_imgs, cropped_ori_003_imgs],  axis=0)\n",
    "cropped_label_imgs = np.concatenate([cropped_label_001_imgs, cropped_label_002_imgs, cropped_label_003_imgs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_003.csv'\n",
    "X_train = cropped_ori_imgs\n",
    "Y_train = cropped_label_imgs\n",
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(X_train,Y_train, csv_path, model_path, input_shape,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/mito_nested_unet_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1\n",
    "filenames = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(ori_imgs)\n",
    "\n",
    "X_test = seped_xy_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_003/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_xy_imgs, X_test\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(ori_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "X_test = seped_yz_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_003/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_yz_imgs, X_test\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(ori_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "X_test = seped_zx_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_003/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_zx_imgs, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_xy, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_xy_003')\n",
    "merged_mito_imgs_xy = merge_imgs(mito_imgs_xy, ori_image_shape)\n",
    "del mito_imgs_xy\n",
    "\n",
    "mito_imgs_yz, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_yz_003')\n",
    "merged_mito_imgs_yz = merge_imgs(mito_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "del mito_imgs_yz\n",
    "\n",
    "mito_imgs_zx, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/pred_zx_003')\n",
    "merged_mito_imgs_zx = merge_imgs(mito_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "del mito_imgs_zx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_ave = merged_mito_imgs_xy * 255 // 3 + merged_mito_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_mito_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_003'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        mito_imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without HITL train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/dataset/cropped_002/resize_10x10x10/')\n",
    "label_imgs_001 , _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/manually_mito_001//', normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst_001 = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250]\n",
    "\n",
    "cropped_ori_001_imgs, cropped_label_001_imgs = make_train_datasets(ori_imgs, label_imgs_001, num_lst_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/without_HITL_mito_nested_unet_001.csv'\n",
    "X_train = cropped_ori_001_imgs\n",
    "Y_train = cropped_label_001_imgs\n",
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/without_HITL_mito_nested_unet_001.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(X_train,Y_train, csv_path, model_path, input_shape,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without HITL pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/models/cropped_002_002/active_learning/without_HITL_mito_nested_unet_001.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=1\n",
    "filenames = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(ori_imgs)\n",
    "\n",
    "X_test = seped_xy_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_xy_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_xy_imgs, X_test\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(ori_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "X_test = seped_yz_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_yz_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_yz_imgs, X_test\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(ori_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "X_test = seped_zx_imgs\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_zx_001/'\n",
    "predict(X_test, model_path, filenames, out_dir, input_shape, num_classes)\n",
    "\n",
    "del  seped_zx_imgs, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_xy, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_xy_001')\n",
    "merged_mito_imgs_xy = merge_imgs(mito_imgs_xy, ori_image_shape)\n",
    "del mito_imgs_xy\n",
    "\n",
    "mito_imgs_yz, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_yz_001')\n",
    "merged_mito_imgs_yz = merge_imgs(mito_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "del mito_imgs_yz\n",
    "\n",
    "mito_imgs_zx, _ = load_Y_gray_with_gaussian('H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/pred_zx_001')\n",
    "merged_mito_imgs_zx = merge_imgs(mito_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "del mito_imgs_zx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_imgs_ave = merged_mito_imgs_xy * 255 // 3 + merged_mito_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_mito_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "out_dir = 'H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/merged_001'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        mito_imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# culc F1 score and create representative imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_img(ori_img, mask_img):\n",
    "    mask_img_rgb = np.zeros((mask_img.shape[0], mask_img.shape[1], 3), np.float32)\n",
    "    mask_img_rgb[:,:,0] = mask_img[:,:,0]\n",
    "    mask_img_rgb[:,:,2] = mask_img[:,:,0]\n",
    "    masked_img = cv2.addWeighted(mask_img_rgb,0.5,cv2.cvtColor(ori_img+0.75, cv2.COLOR_GRAY2BGR),0.6,0)\n",
    "    return masked_img\n",
    "\n",
    "\n",
    "def make_two_mask_img(ori_img, mask_img, raw_img):\n",
    "    mask_img_rgb = np.zeros((mask_img.shape[0], mask_img.shape[1], 3), np.float32)\n",
    "    mask_img_rgb[:,:,2] = mask_img[:,:,0]\n",
    "    mask_img_rgb[:,:,0] = mask_img[:,:,0]\n",
    "    mask_img_rgb[:,:,1] += np.where(\n",
    "        (raw_img[:,:,0]* 255 < 170) & (raw_img[:,:,0]* 255 > 127),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    mask_img_rgb[:,:,2] -= mask_img_rgb[:,:,1]\n",
    "    mask_img_rgb[:,:,0] -= mask_img_rgb[:,:,1]\n",
    "    \n",
    "    masked_img = cv2.addWeighted(mask_img_rgb,0.5,cv2.cvtColor(ori_img+0.75, cv2.COLOR_GRAY2BGR),0.6,0)\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culc_f1(pred, gt):\n",
    "    \n",
    "    PRE = np.count_nonzero((pred*255 > 0.5) & (gt* 255 > 0.5)) / np.count_nonzero(pred*255 > 0.5)\n",
    "    RE = np.count_nonzero((pred*255 > 0.5) & (gt * 255 > 0.5)) / np.count_nonzero(gt*255 > 0.5)\n",
    "    \n",
    "    try:\n",
    "        F1 = 2 * (PRE * RE) / (PRE + RE)\n",
    "        print(f\"Precision: {round(PRE,2)}, Recall: {round(RE,2)}, F1: {round(F1,2)} \")\n",
    "        return round(F1,2)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    except:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n",
      "(248, 1147, 960, 1)\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248, 1147, 960, 1)\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n",
      "(248, 1147, 960, 1)\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png', '0248.png', '0249.png', '0250.png', '0251.png', '0252.png', '0253.png', '0254.png', '0255.png', '0256.png', '0257.png', '0258.png', '0259.png', '0260.png', '0261.png', '0262.png', '0263.png', '0264.png', '0265.png', '0266.png', '0267.png', '0268.png', '0269.png', '0270.png', '0271.png', '0272.png', '0273.png', '0274.png', '0275.png', '0276.png', '0277.png', '0278.png', '0279.png', '0280.png', '0281.png', '0282.png', '0283.png', '0284.png', '0285.png', '0286.png', '0287.png', '0288.png', '0289.png', '0290.png', '0291.png', '0292.png', '0293.png', '0294.png', '0295.png', '0296.png', '0297.png', '0298.png', '0299.png', '0300.png', '0301.png', '0302.png', '0303.png', '0304.png', '0305.png', '0306.png', '0307.png', '0308.png']\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248, 1147, 960, 1)\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png', '0248.png', '0249.png', '0250.png', '0251.png', '0252.png', '0253.png', '0254.png', '0255.png', '0256.png', '0257.png', '0258.png', '0259.png', '0260.png', '0261.png', '0262.png', '0263.png', '0264.png', '0265.png', '0266.png', '0267.png', '0268.png', '0269.png', '0270.png', '0271.png', '0272.png', '0273.png', '0274.png', '0275.png', '0276.png', '0277.png', '0278.png', '0279.png', '0280.png', '0281.png', '0282.png', '0283.png', '0284.png', '0285.png', '0286.png', '0287.png', '0288.png', '0289.png', '0290.png', '0291.png', '0292.png', '0293.png', '0294.png', '0295.png', '0296.png', '0297.png', '0298.png', '0299.png', '0300.png', '0301.png', '0302.png', '0303.png', '0304.png', '0305.png', '0306.png', '0307.png', '0308.png']\n",
      "(309, 1434, 1200, 1)\n"
     ]
    }
   ],
   "source": [
    "ori_80_imgs , _ = load_X_gray('I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002/original//')\n",
    "\n",
    "pred_imgs_001, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_001/\", normalize=False)\n",
    "pred_imgs_002, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_002/\", normalize=False)\n",
    "pred_imgs_003, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_003/\", normalize=False)\n",
    "\n",
    "ori_imgs, _ = load_X_gray(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/dataset/cropped_002/resize_10x10x10/\")\n",
    "wo_pred_imgs, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_without_HITL/merged_001/\", normalize=False)\n",
    "mito_imgs, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/annotations/cropped_002/devided_mito_/\", normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n",
      "(248, 1147, 960, 1)\n",
      "['0000.png', '0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png', '0011.png', '0012.png', '0013.png', '0014.png', '0015.png', '0016.png', '0017.png', '0018.png', '0019.png', '0020.png', '0021.png', '0022.png', '0023.png', '0024.png', '0025.png', '0026.png', '0027.png', '0028.png', '0029.png', '0030.png', '0031.png', '0032.png', '0033.png', '0034.png', '0035.png', '0036.png', '0037.png', '0038.png', '0039.png', '0040.png', '0041.png', '0042.png', '0043.png', '0044.png', '0045.png', '0046.png', '0047.png', '0048.png', '0049.png', '0050.png', '0051.png', '0052.png', '0053.png', '0054.png', '0055.png', '0056.png', '0057.png', '0058.png', '0059.png', '0060.png', '0061.png', '0062.png', '0063.png', '0064.png', '0065.png', '0066.png', '0067.png', '0068.png', '0069.png', '0070.png', '0071.png', '0072.png', '0073.png', '0074.png', '0075.png', '0076.png', '0077.png', '0078.png', '0079.png', '0080.png', '0081.png', '0082.png', '0083.png', '0084.png', '0085.png', '0086.png', '0087.png', '0088.png', '0089.png', '0090.png', '0091.png', '0092.png', '0093.png', '0094.png', '0095.png', '0096.png', '0097.png', '0098.png', '0099.png', '0100.png', '0101.png', '0102.png', '0103.png', '0104.png', '0105.png', '0106.png', '0107.png', '0108.png', '0109.png', '0110.png', '0111.png', '0112.png', '0113.png', '0114.png', '0115.png', '0116.png', '0117.png', '0118.png', '0119.png', '0120.png', '0121.png', '0122.png', '0123.png', '0124.png', '0125.png', '0126.png', '0127.png', '0128.png', '0129.png', '0130.png', '0131.png', '0132.png', '0133.png', '0134.png', '0135.png', '0136.png', '0137.png', '0138.png', '0139.png', '0140.png', '0141.png', '0142.png', '0143.png', '0144.png', '0145.png', '0146.png', '0147.png', '0148.png', '0149.png', '0150.png', '0151.png', '0152.png', '0153.png', '0154.png', '0155.png', '0156.png', '0157.png', '0158.png', '0159.png', '0160.png', '0161.png', '0162.png', '0163.png', '0164.png', '0165.png', '0166.png', '0167.png', '0168.png', '0169.png', '0170.png', '0171.png', '0172.png', '0173.png', '0174.png', '0175.png', '0176.png', '0177.png', '0178.png', '0179.png', '0180.png', '0181.png', '0182.png', '0183.png', '0184.png', '0185.png', '0186.png', '0187.png', '0188.png', '0189.png', '0190.png', '0191.png', '0192.png', '0193.png', '0194.png', '0195.png', '0196.png', '0197.png', '0198.png', '0199.png', '0200.png', '0201.png', '0202.png', '0203.png', '0204.png', '0205.png', '0206.png', '0207.png', '0208.png', '0209.png', '0210.png', '0211.png', '0212.png', '0213.png', '0214.png', '0215.png', '0216.png', '0217.png', '0218.png', '0219.png', '0220.png', '0221.png', '0222.png', '0223.png', '0224.png', '0225.png', '0226.png', '0227.png', '0228.png', '0229.png', '0230.png', '0231.png', '0232.png', '0233.png', '0234.png', '0235.png', '0236.png', '0237.png', '0238.png', '0239.png', '0240.png', '0241.png', '0242.png', '0243.png', '0244.png', '0245.png', '0246.png', '0247.png']\n",
      "(248, 1147, 960, 1)\n"
     ]
    }
   ],
   "source": [
    "pred_imgs_001_raw, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_001_raw//\", normalize=False)\n",
    "pred_imgs_002_raw, _ = load_Y_gray_with_gaussian(\"I:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/cropped_002_002/merged_002_raw//\", normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.79, Recall: 0.76, F1: 0.77 \n",
      "0.77\n",
      "Precision: 0.83, Recall: 0.99, F1: 0.9 \n",
      "0.9\n",
      "Precision: 0.83, Recall: 0.99, F1: 0.9 \n",
      "0.9\n",
      "Precision: 0.78, Recall: 0.73, F1: 0.76 \n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "N = 54\n",
    "y = 850\n",
    "x =  300\n",
    "\n",
    "N_ = N +30\n",
    "y_ = y + 143\n",
    "x_ = x + 120\n",
    "\n",
    "\n",
    "ori_054 = ori_80_imgs[N][y:y+150, x:x+150]\n",
    "pred_001_054 = pred_imgs_001[N][y:y+150, x:x+150]\n",
    "pred_002_054 = pred_imgs_002[N][y:y+150, x:x+150]\n",
    "pred_003_054 = pred_imgs_003[N][y:y+150, x:x+150]\n",
    "pred_wo_054 = wo_pred_imgs[N][y:y+150, x:x+150]\n",
    "\n",
    "mito_054 = mito_imgs[N_][y_:y_+150, x_:x_+150]\n",
    "first_054 = make_two_mask_img(\n",
    "    ori_054,\n",
    "    pred_001_054,\n",
    "    pred_imgs_001_raw[N][y:y+150, x:x+150] / 255\n",
    ")\n",
    "second_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_002_054\n",
    ")\n",
    "third_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_003_054\n",
    ")\n",
    "wo_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_wo_054\n",
    ")\n",
    "gt_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    mito_054\n",
    ")\n",
    "original_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    np.zeros((150, 150, 1), np.float32)\n",
    ")\n",
    "\"\"\"\n",
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/for_paper/cropped_002_002/first_054_\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/000.png\",\n",
    "    denormalize_y(original_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/001.png\",\n",
    "    denormalize_y(first_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/002.png\",\n",
    "    denormalize_y(second_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/003.png\",\n",
    "    denormalize_y(third_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/004.png\",\n",
    "    denormalize_y(wo_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/005.png\",\n",
    "    denormalize_y(gt_054)\n",
    ")\n",
    "\"\"\"\n",
    "FIRST = culc_f1(pred_001_054, mito_054)\n",
    "print(FIRST)\n",
    "\n",
    "SECOND = culc_f1(pred_002_054, mito_054)\n",
    "print(SECOND)\n",
    "\n",
    "THIRD = culc_f1(pred_003_054, mito_054)\n",
    "print(THIRD)\n",
    "\n",
    "DL = culc_f1(pred_wo_054, mito_054)\n",
    "print(DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99, Recall: 0.91, F1: 0.95 \n",
      "0.95\n",
      "Precision: 0.98, Recall: 0.96, F1: 0.97 \n",
      "0.97\n",
      "Precision: 0.99, Recall: 0.96, F1: 0.98 \n",
      "0.98\n",
      "Precision: 0.99, Recall: 0.95, F1: 0.97 \n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "N = 92\n",
    "y = 800\n",
    "x =  350\n",
    "\n",
    "N_ = N +30\n",
    "y_ = y + 143\n",
    "x_ = x + 120\n",
    "\n",
    "\n",
    "ori_054 = ori_80_imgs[N][y:y+150, x:x+150]\n",
    "pred_001_054 = pred_imgs_001[N][y:y+150, x:x+150]\n",
    "pred_002_054 = pred_imgs_002[N][y:y+150, x:x+150]\n",
    "pred_003_054 = pred_imgs_003[N][y:y+150, x:x+150]\n",
    "pred_wo_054 = wo_pred_imgs[N][y:y+150, x:x+150]\n",
    "mito_054 = mito_imgs[N_][y_:y_+150, x_:x_+150]\n",
    "\n",
    "second_054 = make_two_mask_img(\n",
    "    ori_054,\n",
    "    pred_002_054,\n",
    "    pred_imgs_002_raw[N][y:y+150, x:x+150] / 255\n",
    ")\n",
    "\n",
    "first_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_001_054\n",
    ")\n",
    "\n",
    "third_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_003_054\n",
    ")\n",
    "\n",
    "wo_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_wo_054\n",
    ")\n",
    "\n",
    "gt_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    mito_054\n",
    ")\n",
    "\n",
    "original_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    np.zeros((150, 150, 1), np.float32)\n",
    ")\n",
    "\"\"\"\n",
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/for_paper/cropped_002_002/second_092_\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/000.png\",\n",
    "    denormalize_y(original_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/001.png\",\n",
    "    denormalize_y(first_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/002.png\",\n",
    "    denormalize_y(second_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/003.png\",\n",
    "    denormalize_y(third_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/004.png\",\n",
    "    denormalize_y(wo_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/005.png\",\n",
    "    denormalize_y(gt_054)\n",
    ")\n",
    "\"\"\"\n",
    "FIRST = culc_f1(pred_001_054, mito_054)\n",
    "print(FIRST)\n",
    "\n",
    "SECOND = culc_f1(pred_002_054, mito_054)\n",
    "print(SECOND)\n",
    "\n",
    "THIRD = culc_f1(pred_003_054, mito_054)\n",
    "print(THIRD)\n",
    "\n",
    "DL = culc_f1(pred_wo_054, mito_054)\n",
    "print(DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.75, Recall: 0.93, F1: 0.83 \n",
      "0.83\n",
      "Precision: 0.76, Recall: 0.98, F1: 0.86 \n",
      "0.86\n",
      "Precision: 0.76, Recall: 0.98, F1: 0.86 \n",
      "0.86\n",
      "Precision: 0.75, Recall: 0.91, F1: 0.82 \n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "N = 42\n",
    "y = 850\n",
    "x =  300\n",
    "\n",
    "N_ = N +30\n",
    "y_ = y + 143\n",
    "x_ = x + 120\n",
    "\n",
    "\n",
    "ori_054 = ori_80_imgs[N][y:y+150, x:x+150]\n",
    "pred_001_054 = pred_imgs_001[N][y:y+150, x:x+150]\n",
    "pred_002_054 = pred_imgs_002[N][y:y+150, x:x+150]\n",
    "pred_003_054 = pred_imgs_003[N][y:y+150, x:x+150]\n",
    "pred_wo_054 = wo_pred_imgs[N][y:y+150, x:x+150]\n",
    "mito_054 = mito_imgs[N_][y_:y_+150, x_:x_+150]\n",
    "\n",
    "first_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_001_054\n",
    ")\n",
    "\n",
    "second_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_002_054\n",
    ")\n",
    "\n",
    "third_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_003_054\n",
    ")\n",
    "\n",
    "wo_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_wo_054\n",
    ")\n",
    "\n",
    "gt_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    mito_054\n",
    ")\n",
    "\n",
    "original_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    np.zeros((150, 150, 1), np.float32)\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/for_paper/cropped_002_002/40_\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/000.png\",\n",
    "    denormalize_y(original_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/001.png\",\n",
    "    denormalize_y(first_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/002.png\",\n",
    "    denormalize_y(second_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/003.png\",\n",
    "    denormalize_y(third_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/004.png\",\n",
    "    denormalize_y(wo_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/005.png\",\n",
    "    denormalize_y(gt_054)\n",
    ")\"\"\"\n",
    "\n",
    "FIRST = culc_f1(pred_001_054, mito_054)\n",
    "print(FIRST)\n",
    "\n",
    "SECOND = culc_f1(pred_002_054, mito_054)\n",
    "print(SECOND)\n",
    "\n",
    "THIRD = culc_f1(pred_003_054, mito_054)\n",
    "print(THIRD)\n",
    "\n",
    "DL = culc_f1(pred_wo_054, mito_054)\n",
    "print(DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.99, Recall: 0.67, F1: 0.8 \n",
      "0.8\n",
      "Precision: 0.99, Recall: 0.98, F1: 0.98 \n",
      "0.98\n",
      "Precision: 0.99, Recall: 0.98, F1: 0.98 \n",
      "0.98\n",
      "Precision: 0.99, Recall: 0.68, F1: 0.81 \n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "N = 70\n",
    "y = 825\n",
    "x =  320\n",
    "\n",
    "N_ = N +30\n",
    "y_ = y + 143\n",
    "x_ = x + 120\n",
    "\n",
    "\n",
    "ori_054 = ori_80_imgs[N][y:y+150, x:x+150]\n",
    "pred_001_054 = pred_imgs_001[N][y:y+150, x:x+150]\n",
    "pred_002_054 = pred_imgs_002[N][y:y+150, x:x+150]\n",
    "pred_003_054 = pred_imgs_003[N][y:y+150, x:x+150]\n",
    "pred_wo_054 = wo_pred_imgs[N][y:y+150, x:x+150]\n",
    "mito_054 = mito_imgs[N_][y_:y_+150, x_:x_+150]\n",
    "\n",
    "first_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_001_054\n",
    ")\n",
    "\n",
    "second_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_002_054\n",
    ")\n",
    "\n",
    "third_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_003_054\n",
    ")\n",
    "\n",
    "wo_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    pred_wo_054\n",
    ")\n",
    "\n",
    "gt_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    mito_054\n",
    ")\n",
    "\n",
    "original_054 = make_mask_img(\n",
    "    ori_054,\n",
    "    np.zeros((150, 150, 1), np.float32)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "out_dir = \"H:/DeepLearningData/research_010_NIH3T3/shCtrl_001_realignment/active_learning_dataset/for_paper/cropped_002_002/70_\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/000.png\",\n",
    "    denormalize_y(original_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/001.png\",\n",
    "    denormalize_y(first_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/002.png\",\n",
    "    denormalize_y(second_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/003.png\",\n",
    "    denormalize_y(third_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/004.png\",\n",
    "    denormalize_y(wo_054)\n",
    ")\n",
    "\n",
    "cv2.imwrite(\n",
    "    f\"{out_dir}/005.png\",\n",
    "    denormalize_y(gt_054)\n",
    ")\"\"\"\n",
    "\n",
    "FIRST = culc_f1(pred_001_054, mito_054)\n",
    "print(FIRST)\n",
    "\n",
    "SECOND = culc_f1(pred_002_054, mito_054)\n",
    "print(SECOND)\n",
    "\n",
    "THIRD = culc_f1(pred_003_054, mito_054)\n",
    "print(THIRD)\n",
    "\n",
    "DL = culc_f1(pred_wo_054, mito_054)\n",
    "print(DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
