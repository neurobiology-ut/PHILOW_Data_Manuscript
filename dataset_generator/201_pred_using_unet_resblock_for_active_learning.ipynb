{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f69ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]= \"true\"\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from skimage import morphology\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#値を-1から1に正規化する関数\n",
    "def normalize_x(image):\n",
    "    return image / 127.5 - 1\n",
    "\n",
    "\n",
    "#値を0から1正規化する関数\n",
    "def normalize_y(image):\n",
    "    return image / 255\n",
    "\n",
    "\n",
    "#値を0から255に戻す関数\n",
    "def denormalize_y(image):\n",
    "    return image * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bbd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# インプット画像を読み込む関数\n",
    "def load_X_gray(folder_path):\n",
    "    \n",
    "    image_files = []\n",
    "\n",
    "    #image_files = os.listdir(folder_path)\n",
    "       \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    #image_files = image_files[1:]\n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1), np.float32)\n",
    "    for i, image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        #image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = image[:, :, np.newaxis]\n",
    "        images[i] = normalize_x(image)\n",
    "    \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images, image_files\n",
    "\n",
    "\n",
    "def load_Y_gray(folder_path, thresh = None , normalize = False, g_size = None):\n",
    "    image_files = []\n",
    "    #image_files = os.listdir(folder_path)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros(\n",
    "        (len(image_files), img.shape[0], img.shape[1], 1) ,np.float32\n",
    "    )\n",
    "    \n",
    "    for i , image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(\n",
    "            folder_path + os.sep + image_file ,\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "        #print(image.shape)\n",
    "        \n",
    "        # ぼかし処理\n",
    "        if g_size:\n",
    "            image = cv2.GaussianBlur(\n",
    "                image, (g_size, g_size), 0\n",
    "            )        \n",
    "        \n",
    "        if thresh:\n",
    "            ret , image = cv2.threshold(image , thresh , 255 , cv2.THRESH_BINARY)\n",
    "        image = image[ : , : , np.newaxis]\n",
    "        if normalize:\n",
    "            images[i] = normalize_y(image)\n",
    "        else:\n",
    "            images[i] = image\n",
    "            \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images , image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a01265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_dice_coeff(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                          (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ae9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_resnet_512(input_shape=(512, 512, 1), num_classes=3):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    res0 = Conv2D(16, (1, 1), padding = 'same',  use_bias = False)(inputs)\n",
    "    down0 = Conv2D(16, (3, 3), padding='same')(inputs)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(16, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Add()([res0, down0])\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    \n",
    "    res1 = Conv2D(32, (1, 1), padding = 'same',  use_bias = False)(down0_pool)\n",
    "    down1 = Conv2D(32, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(32, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Add()([res1, down1])\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    \n",
    "    res2 = Conv2D(64, (1, 1), padding = 'same',  use_bias = False)(down1_pool)\n",
    "    down2 = Conv2D(64, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(64, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Add()([res2, down2])\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    \n",
    "    res3 = Conv2D(128, (1, 1), padding = 'same',  use_bias = False)(down2_pool)\n",
    "    down3 = Conv2D(128, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3 = Conv2D(128, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Add()([res3, down3])\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    \n",
    "    res4 = Conv2D(256, (1, 1), padding = 'same',  use_bias = False)(down3_pool)\n",
    "    down4 = Conv2D(256, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4 = Conv2D(256, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Add()([res4, down4])\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    \n",
    "    res5 = Conv2D(512, (1, 1), padding = 'same',  use_bias = False)(down4_pool)\n",
    "    down5 = Conv2D(512, (3, 3), padding='same')(down4_pool)\n",
    "    down5 = BatchNormalization()(down5)\n",
    "    down5 = Activation('relu')(down5)\n",
    "    down5 = Conv2D(512, (3, 3), padding='same')(down5)\n",
    "    down5 = BatchNormalization()(down5)\n",
    "    down5 = Add()([res5, down5])\n",
    "    down5 = Activation('relu')(down5)\n",
    "    down5_pool = MaxPooling2D((2, 2), strides=(2, 2))(down5)\n",
    "    \n",
    "    res6 = Conv2D(1024, (1, 1), padding = 'same',  use_bias = False)(down5_pool)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down5_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Add()([res6, center])\n",
    "    center = Activation('relu')(center)\n",
    "    \n",
    "    up5 = UpSampling2D((2, 2))(center)\n",
    "    up5 = Conv2D(512, (2, 2), padding = 'same')(up5)\n",
    "    up5 = Activation('relu')(up5)\n",
    "    up5 = concatenate([up5, down5], axis = 3)\n",
    "    res_up5 = Conv2D(512, (1, 1), padding = 'same', use_bias = False)(up5)\n",
    "    up5 = Conv2D(512, (3, 3), padding = 'same')(up5)\n",
    "    up5 = BatchNormalization()(up5)\n",
    "    up5 = Activation('relu')(up5)\n",
    "    up5 = Conv2D(512, (3, 3), padding = 'same')(up5)\n",
    "    up5 = BatchNormalization()(up5)\n",
    "    up5 = Add()([res_up5, up5])\n",
    "    up5 = Activation('relu')(up5)\n",
    "    \n",
    "    up4 = UpSampling2D((2, 2))(up5)\n",
    "    up4 = Conv2D(256, (2, 2), padding = 'same')(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = concatenate([up4, down4], axis = 3)\n",
    "    res_up4 = Conv2D(256, (1, 1), padding = 'same', use_bias = False)(up4)\n",
    "    up4 = Conv2D(256, (3, 3), padding = 'same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(256, (3, 3), padding = 'same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Add()([res_up4, up4])\n",
    "    up4 = Activation('relu')(up4)\n",
    "    \n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = Conv2D(128, (2, 2), padding = 'same')(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = concatenate([up3, down3], axis = 3)\n",
    "    res_up3 = Conv2D(128, (1, 1), padding = 'same', use_bias = False)(up3)\n",
    "    up3 = Conv2D(128, (3, 3), padding = 'same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(128, (3, 3), padding = 'same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Add()([res_up3, up3])\n",
    "    up3 = Activation('relu')(up3)\n",
    "    \n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = Conv2D(64, (2, 2), padding = 'same')(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = concatenate([up2, down2], axis = 3)\n",
    "    res_up2 = Conv2D(64, (1, 1), padding = 'same', use_bias = False)(up2)\n",
    "    up2 = Conv2D(64, (3, 3), padding = 'same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(64, (3, 3), padding = 'same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Add()([res_up2, up2])\n",
    "    up2 = Activation('relu')(up2)\n",
    "    \n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = Conv2D(32, (2, 2), padding = 'same')(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = concatenate([up1, down1], axis = 3)\n",
    "    res_up1 = Conv2D(32, (1, 1), padding = 'same', use_bias = False)(up1)\n",
    "    up1 = Conv2D(32, (3, 3), padding = 'same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(32, (3, 3), padding = 'same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Add()([res_up1, up1])\n",
    "    up1 = Activation('relu')(up1)\n",
    "    \n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = Conv2D(16, (2, 2), padding = 'same')(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = concatenate([up0, down0], axis = 3)\n",
    "    res_up0 = Conv2D(16, (1, 1), padding = 'same', use_bias = False)(up0)\n",
    "    up0 = Conv2D(16, (3, 3), padding = 'same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(16, (3, 3), padding = 'same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Add()([res_up0, up0])\n",
    "    up0 = Activation('relu')(up0)\n",
    "    \n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0)\n",
    "    #classify = Conv2D(num_classes, (1, 1), padding = 'same', activation='softmax')(up0)\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8391663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_rgb_imgs(images):\n",
    "    \n",
    "    '''\n",
    "        512 x 512に分割する\n",
    "        端の50pxをのりしろとする\n",
    "        空欄箇所は-1（黒）にする\n",
    "        height, widthが412未満の場合は変数を-1に変更\n",
    "    '''\n",
    "    \n",
    "    H = -(-images.shape[1]//412)\n",
    "    W = -(-images.shape[2]//412)\n",
    "    \n",
    "    diveded_imgs = np.zeros(( images.shape[0]*H*W, 512, 512, 1), np.float32)\n",
    "    print(H,W)\n",
    "    \n",
    "    for z in range(images.shape[0]):\n",
    "        image = images[z]\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                cropped_img = np.zeros((512, 512, 1), np.float32)\n",
    "                #cropped_img -= 1\n",
    "                \n",
    "                if images.shape[1] < 412:\n",
    "                    h = -1\n",
    "                if images.shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:images.shape[2]+50, 0] = image[0:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:512, 0] = image[0:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:images.shape[1]+50, 0:images.shape[2]-412*W-50, 0] = image[0:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        cropped_img[50:images.shape[1]+50, :, 0] = image[0:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:512, 50:images.shape[2]+50, 0] = image[0:462, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:512, 50:512, 0] = image[0:462, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:512, 0:images.shape[2]-412*W-50, 0] = image[0:462, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[50:512, 0:images.shape[2]-412*(W-1)-50, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:images.shape[2]+50, 0] = image[h*412-50:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:512, 0] = image[h*412-50:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, :, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                        cropped_img[:, 50:images.shape[2]+50, 0] = image[h*412-50:(h+1)*412+50, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        #cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        #cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]         \n",
    "                        except:\n",
    "                            try:\n",
    "                                 cropped_img[:, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                            except:\n",
    "                                 cropped_img[0:images.shape[1]-412*(H-1)-50, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                h = max(0, h)\n",
    "                w = max(0, w)\n",
    "                diveded_imgs[z*H*W+ w*H+h] = cropped_img\n",
    "                #print(z*H*W+ w*H+h)\n",
    "                \n",
    "    return diveded_imgs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def divide_gray_imgs(images):\n",
    "    \n",
    "    '''\n",
    "        512 x 512に分割する\n",
    "        端の50pxをのりしろとする\n",
    "        空欄箇所は-1（黒）にする\n",
    "        height, widthが412未満の場合は変数を-1に変更\n",
    "    '''\n",
    "    \n",
    "    H = -(-images.shape[1]//412)\n",
    "    W = -(-images.shape[2]//412)\n",
    "    \n",
    "    diveded_imgs = np.zeros(( images.shape[0]*H*W, 512, 512, 1), np.float32)\n",
    "    print(H,W)\n",
    "    \n",
    "    for z in range(images.shape[0]):\n",
    "        image = images[z]\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                cropped_img = np.zeros((512, 512, 1), np.float32)\n",
    "                cropped_img -= 1\n",
    "                \n",
    "                if images.shape[1] < 412:\n",
    "                    h = -1\n",
    "                if images.shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:images.shape[2]+50, 0] = image[0:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:512, 0] = image[0:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:images.shape[1]+50, 0:images.shape[2]-412*W-50, 0] = image[0:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        cropped_img[50:images.shape[1]+50, :, 0] = image[0:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:512, 50:images.shape[2]+50, 0] = image[0:462, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:512, 50:512, 0] = image[0:462, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:512, 0:images.shape[2]-412*W-50, 0] = image[0:462, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[50:512, 0:images.shape[2]-412*(W-1)-50, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:images.shape[2]+50, 0] = image[h*412-50:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:512, 0] = image[h*412-50:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, :, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                        cropped_img[:, 50:images.shape[2]+50, 0] = image[h*412-50:(h+1)*412+50, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        #cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        #cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]         \n",
    "                        except:\n",
    "                            try:\n",
    "                                 cropped_img[:, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                            except:\n",
    "                                 cropped_img[0:images.shape[1]-412*(H-1)-50, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                h = max(0, h)\n",
    "                w = max(0, w)\n",
    "                diveded_imgs[z*H*W+ w*H+h] = cropped_img\n",
    "                #print(z*H*W+ w*H+h)\n",
    "                \n",
    "    return diveded_imgs\n",
    "\n",
    "\n",
    "def divide_imgs(images):\n",
    "    if images.shape[3] == 1:\n",
    "        return divide_gray_imgs(images)\n",
    "    else:\n",
    "        return np.concatenate( list( divide_rgb_imgs(images[:,:,:,c][..., np.newaxis]) for c in range(images.shape[3]) ), axis = 3 )\n",
    "            \n",
    "    \n",
    "    \n",
    "def merge_imgs(imgs, original_image_shape):\n",
    "    \n",
    "    '''\n",
    "        元のサイズに合体させる\n",
    "        original_image_shapeはoriginal_image.shapeで与えられる、(z, h, w, channel)のタプル型\n",
    "    '''\n",
    "    \n",
    "    merged_imgs = np.zeros((original_image_shape[0], original_image_shape[1], original_image_shape[2], 1), np.float32)\n",
    "    H = -(-original_image_shape[1]//412)\n",
    "    W = -(-original_image_shape[2]//412)    \n",
    "    \n",
    "    for z in range(original_image_shape[0]):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "\n",
    "                if original_image_shape[1] < 412:\n",
    "                    h = -1\n",
    "                if original_image_shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                #print(z*H*W+ max(w, 0)*H+max(h, 0))    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:(h+1)*412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]  \n",
    "                        \n",
    "    return merged_imgs\n",
    "\n",
    "\n",
    "def load_Y_gray_with_gaussian(folder_path, thresh = None , normalize = True, g_size = None):\n",
    "    image_files = []\n",
    "    #image_files = os.listdir(folder_path)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros(\n",
    "        (len(image_files), img.shape[0], img.shape[1], 1) ,np.float32\n",
    "    )\n",
    "    \n",
    "    for i , image_file in enumerate(image_files):\n",
    "        image = cv2.imread(\n",
    "            folder_path + os.sep + image_file ,\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "        \n",
    "        # ぼかし処理\n",
    "        if g_size:\n",
    "            image = cv2.GaussianBlur(\n",
    "                image, (g_size, g_size), 0\n",
    "            )\n",
    "        \n",
    "        if thresh:\n",
    "            ret , image = cv2.threshold(image , thresh , 255 , cv2.THRESH_BINARY)\n",
    "        image = image[ : , : , np.newaxis]\n",
    "        if normalize:\n",
    "            images[i] = normalize_y(image)\n",
    "        else:\n",
    "            images[i] = image\n",
    "            \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images , image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_80_percents_data(imgs):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args : \n",
    "            imgs (numpy.ndarray) : Z, Y, X, 1\n",
    "        \n",
    "        Returns :\n",
    "            imgs (numpy.ndarray) : Z, Y, X, 1\n",
    "            \n",
    "        Memo :\n",
    "            z, y, x　の全ての上下左右縦横10%を捨てる\n",
    "    \"\"\"\n",
    "    z_range = [int(imgs.shape[0] * 0.1), int(imgs.shape[0] * 0.9)]\n",
    "    y_range = [int(imgs.shape[1] * 0.1), int(imgs.shape[1] * 0.9)]\n",
    "    x_range = [int(imgs.shape[2] * 0.1), int(imgs.shape[2] * 0.9)]\n",
    "    \n",
    "    return imgs[z_range[0]:z_range[1], y_range[0]:y_range[1], x_range[0]:x_range[1], :]\n",
    "\n",
    "\n",
    "def make_cristae_train_datasets(ori_images, label_images, num_list):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args : \n",
    "            ori_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            label_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            num_list (list) : num\n",
    "            \n",
    "        Returns : \n",
    "            train_ori_images (numpy.ndarray) : Z, Y, X, 1\n",
    "            train_label_images (numpy.ndarray) : Z, Y, X, 2\n",
    "            \n",
    "        Memo:\n",
    "            num_listに入っている画像を抽出\n",
    "            label_images は \"1:lamellar, 2:tubular\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    train_ori_images = list()\n",
    "    train_label_images = list()\n",
    "    for num in num_list:\n",
    "        ori_image = ori_images[num]\n",
    "        label_image = label_images[num]\n",
    "        \n",
    "        # 切り出す範囲を指定\n",
    "        x_range = [0, ori_image.shape[0]]\n",
    "        y_range = [0, ori_image.shape[1]]\n",
    "        \n",
    "        train_ori_images.append(ori_image[x_range[0]:x_range[1], y_range[0]:y_range[1], :])\n",
    "        train_label_images.append(label_image[x_range[0]:x_range[1], y_range[0]:y_range[1], :])\n",
    "        \n",
    "    train_label_images_001 = np.where(\n",
    "        np.array(train_label_images) == 1,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    train_label_images_002 = np.where(\n",
    "        np.array(train_label_images) == 2,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "        \n",
    "    cropped_ori_images = divide_gray_imgs(np.array(train_ori_images))\n",
    "    cropped_label_images_001 = divide_gray_imgs(np.array(train_label_images_001))\n",
    "    cropped_label_images_002 = divide_gray_imgs(np.array(train_label_images_002))\n",
    "    \n",
    "    cropped_ori_images = np.where(\n",
    "        cropped_ori_images == -1,\n",
    "        1,\n",
    "        cropped_ori_images\n",
    "    )\n",
    "    \n",
    "    cropped_label_images_001 = np.where(\n",
    "        cropped_label_images_001 == -1,\n",
    "        0,\n",
    "        cropped_label_images_001\n",
    "    )\n",
    "    \n",
    "    cropped_label_images_002 = np.where(\n",
    "        cropped_label_images_002 == -1,\n",
    "        0,\n",
    "        cropped_label_images_002\n",
    "    )\n",
    "    cropped_label_images = np.concatenate((cropped_label_images_001, cropped_label_images_002, np.zeros(cropped_label_images_001.shape)), axis = 3)\n",
    "        \n",
    "    return cropped_ori_images, cropped_label_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03592144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_white_mask_ori_img(ori_img, mask_img):\n",
    "    \n",
    "    masked_img = np.zeros(\n",
    "        (ori_img.shape[0], ori_img.shape[1], ori_img.shape[2], 1),\n",
    "        np.float32\n",
    "    )\n",
    "    print(masked_img.shape)\n",
    "    print(ori_img.shape)\n",
    "    print(mask_img.shape)\n",
    "    \n",
    "    for i in range(ori_img.shape[0]):\n",
    "        masked_img[:,:,:,0][i] = np.where(\n",
    "            mask_img[:,:,:,0][i] == 1,\n",
    "            ori_img[:,:,:,-1][i],\n",
    "            1\n",
    "        )\n",
    "        \n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d526eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_margin(imgs):\n",
    "    \n",
    "    \"\"\"\n",
    "        412の倍数のH,Wにする\n",
    "    \"\"\"\n",
    "    \n",
    "    original_image_shape = imgs.shape\n",
    "    H = -(-original_image_shape[1]//412)\n",
    "    W = -(-original_image_shape[2]//412) \n",
    "    made_imgs = np.zeros(\n",
    "        (original_image_shape[0], H*412, W*412, 1), \n",
    "        np.float32\n",
    "    )\n",
    "    \n",
    "    start_h = (H*412 - original_image_shape[1]) // 2\n",
    "    start_w = (W*412 - original_image_shape[2]) // 2\n",
    "    \n",
    "    made_imgs[:, start_h:start_h+original_image_shape[1], start_w:start_w+original_image_shape[2], :] = imgs\n",
    "    return made_imgs\n",
    "\n",
    "\n",
    "def delete_margin(imgs, original_image_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "        marginを削除\n",
    "    \"\"\"\n",
    "    \n",
    "    H = -(-original_image_shape[1]//412)\n",
    "    W = -(-original_image_shape[2]//412)\n",
    "    \n",
    "    start_h = (H*412 - original_image_shape[1]) // 2\n",
    "    start_w = (W*412 - original_image_shape[2]) // 2\n",
    "    \n",
    "    return imgs[:, start_h:start_h+original_image_shape[1], start_w:start_w+original_image_shape[2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b862ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後のU-Netによる予測を行う関数\n",
    "def predict(X_test, model_path, filenames, out_dir, input_shape=(512, 512, 1), num_classes=1):\n",
    "\n",
    "    # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "    \n",
    "    model = get_unet_resnet_512(input_shape=input_shape, num_classes=num_classes)\n",
    "    \n",
    "    model.load_weights(model_path)\n",
    "    BATCH_SIZE = 1\n",
    "    Y_pred = model.predict(X_test, BATCH_SIZE)\n",
    "    \n",
    "    print(Y_pred.shape)\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "    \n",
    "    if Y_pred.shape[3]!=1:\n",
    "        num = Y_pred.shape[3]\n",
    "        for n in range(num):\n",
    "            os.makedirs(os.path.join(out_dir,str(n+1)), exist_ok=True)\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            for n in range(num):\n",
    "                os.makedirs(os.path.join(out_dir,str(n+1)), exist_ok=True)\n",
    "            # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "            #img = cv2.imread('512/hira/For_Seika/learning/original/'+ file_names[i], cv2.IMREAD_GRAYSCALE)\n",
    "            #y = cv2.resize(y, (img.shape[1], img.shape[0]))\n",
    "                cv2.imwrite(os.path.join(out_dir, str(n+1) , str(i).zfill(6) + '.png'), denormalize_y(y[:,:,n]))\n",
    "        \n",
    "    else:\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "            #img = cv2.imread('512/hira/For_Seika/learning/original/'+ file_names[i], cv2.IMREAD_GRAYSCALE)\n",
    "            #y = cv2.resize(y, (img.shape[1], img.shape[0]))\n",
    "            cv2.imwrite(os.path.join(out_dir , str(i).zfill(6) + '.png'), denormalize_y(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06370b66",
   "metadata": {},
   "source": [
    "# shCtrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9199e",
   "metadata": {},
   "source": [
    "## cropped_001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabfbe0",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a42860",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca639801",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc399a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f67796",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6dce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce84ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca29fa0",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63282467",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934a2bd",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0344d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1994f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2335f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc8a3b",
   "metadata": {},
   "source": [
    "### pred_004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_004_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ea6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41682f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90486afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_004/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_004/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_004/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_004/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_004/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/manually_cristae_004/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf8cbc",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_001/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_001/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d6689",
   "metadata": {},
   "source": [
    "## cropped_002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c9a7c",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931691a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0245d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c389d07",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d484a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1c6c2",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1261d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c047607",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09079637",
   "metadata": {},
   "source": [
    "### pred_004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f36fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_004_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40909f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_004/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_004/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_004/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_004/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_004/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/manually_cristae_004/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e94f71",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_002/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c067867",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ca0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_002/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626a0d7",
   "metadata": {},
   "source": [
    "## cropped_003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a62ed",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_003/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_003/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de36d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b855cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779911c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a65b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751d668",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb823895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_003/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_003/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8242400",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b487157",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d28210",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_003/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_003/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5578072",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ba737",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa863db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_003/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e415a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_003/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab2bde",
   "metadata": {},
   "source": [
    "## cropped_004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8f1d5",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_004/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_004/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cad957",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973518e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f71ffb",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_004/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_004/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6295ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ede49",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce36357",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c856a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9482a",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_004/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_004/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd283dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb78515",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51efe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be8269",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_004/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c19ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27250fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_004/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e483b8",
   "metadata": {},
   "source": [
    "## cropped_005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79d950",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c82062",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e22715",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae2d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9f046",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5977e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763434da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d81c0",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd529987",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6ebf7",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd083ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/dataset/cropped_005/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebeb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shCtrl_003/annotations/cropped_005/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b0869",
   "metadata": {},
   "source": [
    "# shOPA1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0e44c",
   "metadata": {},
   "source": [
    "## cropped_001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23449833",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d38613",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57abddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74827ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459fcb1",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73791f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59365d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a60b5",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c71c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be2bba",
   "metadata": {},
   "source": [
    "### pred_004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afffc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_004_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e26df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_004/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_004/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81701a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_004/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_004/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_004/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_004/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359bfc09",
   "metadata": {},
   "source": [
    "### pred_005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c408e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_005_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c95515",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a42fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_005/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_005/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_005/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_005/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_005/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_005/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_005/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_005/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_005/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_005/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_005/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_005/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4864c9",
   "metadata": {},
   "source": [
    "### pred_006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48055ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_006_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_006/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_006/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_006/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01039fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_006/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_006/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_006/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_006/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351cd3f",
   "metadata": {},
   "source": [
    "### pred_007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_001/cristae_active_learning/cristae_unet_resblock_007_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_007/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_007/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_007/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_007/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_006/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_006/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_006/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_006/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efda352",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_007/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_007/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_007/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/manually_cristae_007/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee6644",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723dd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_001/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_007/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_007/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_007/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13da183",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_xy_007/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_yz_007/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/cristae_pred_zx_007/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_001/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde08fcd",
   "metadata": {},
   "source": [
    "## cropped_002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba4741",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7875a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c997b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85886ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a8f84",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4dc37f",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d79df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b36580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33046d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a65ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4a296",
   "metadata": {},
   "source": [
    "### pred_004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da012d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_004_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_004/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901edd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf89633",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_004/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_004/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_004/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_004/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_004/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_004/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_004/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_004/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_004/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_004/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_004/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_004/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73b5d9",
   "metadata": {},
   "source": [
    "### pred_005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_005_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_005/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff294fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_005/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_005/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_005/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_005/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec71996",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_005/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_005/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_005/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_005/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_005/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_005/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_005/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_005/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5037a46",
   "metadata": {},
   "source": [
    "### pred_006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d859df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_006_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f04bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_006/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8902845",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e823a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_006/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_006/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_006/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_006/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805eed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_006/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_006/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_006/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_006/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_006/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_006/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_006/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_006/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fb7da",
   "metadata": {},
   "source": [
    "### pred_007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_002/cristae_active_learning/cristae_unet_resblock_007_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59282f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_007/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_007/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_007/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_007/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_007/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_007/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_007/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_007/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_007/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_007/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_007/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_007/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/manually_cristae_007/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635f796",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_002/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_007/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_007/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_007/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb34f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_xy_007/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_yz_007/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/cristae_pred_zx_007/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_002/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffaf905",
   "metadata": {},
   "source": [
    "## cropped_003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c65a12",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_003/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_003/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de133a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6d5923",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb872b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_003/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_003/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc303a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca96332",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693382ee",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d45550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_003/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a936954",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_003/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c335686",
   "metadata": {},
   "source": [
    "## cropped_004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64fe3c",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_004/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_004/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5faff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e974cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24439c8",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfcc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_004/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_004/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3082973",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c22118",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293128c4",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_004/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ab574",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6bfd6",
   "metadata": {},
   "source": [
    "## cropped_005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a91de6",
   "metadata": {},
   "source": [
    "### pred_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5be36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_001_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59299342",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_001/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e56095",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_001/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_001/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_001/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_001/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9192101",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_001/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_001/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_001/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_001/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4540c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_001/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_001/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_001/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/manually_cristae_001/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e48e05",
   "metadata": {},
   "source": [
    "### pred_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d31cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_002_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_002/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e86425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_002/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_002/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_002/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_002/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_002/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_002/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_002/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_002/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_002/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_002/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_002/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/manually_cristae_002/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e76147",
   "metadata": {},
   "source": [
    "### pred_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7308fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_005/resize_10x10x10')\n",
    "mito_imgs , _ = load_Y_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/devided_mito//')\n",
    "\n",
    "model_path = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/models/cropped_005/cristae_active_learning/cristae_unet_resblock_003_weights.hdf5'\n",
    "input_shape=(512, 512, 1)\n",
    "num_classes=3\n",
    "filenames = _\n",
    "\n",
    "masked_imgs = make_white_mask_ori_img(ori_imgs, mito_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seped_xy_imgs = divide_imgs(masked_imgs)\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_xy_imgs.shape[0]):\n",
    "    if np.size(seped_xy_imgs[i]) != np.sum(seped_xy_imgs[i] == -1) + np.sum(seped_xy_imgs[i] == 1):\n",
    "        target_imgs.append(seped_xy_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_xy_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_yz_imgs = divide_imgs(masked_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_yz_imgs.shape[0]):\n",
    "    if np.size(seped_yz_imgs[i]) != np.sum(seped_yz_imgs[i] == -1) + np.sum(seped_yz_imgs[i] == 1):\n",
    "        target_imgs.append(seped_yz_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_yz_imgs, X_test, target_imgs, target_imgs_lst\n",
    "\n",
    "\n",
    "seped_zx_imgs = divide_imgs(masked_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "target_imgs = []\n",
    "target_imgs_lst = []\n",
    "for i in range(seped_zx_imgs.shape[0]):\n",
    "    if np.size(seped_zx_imgs[i]) != np.sum(seped_zx_imgs[i] == -1) + np.sum(seped_zx_imgs[i] == 1):\n",
    "        target_imgs.append(seped_zx_imgs[i])\n",
    "        target_imgs_lst.append(str(i).zfill(6))\n",
    "target_imgs = np.array(target_imgs)\n",
    "\n",
    "X_test = target_imgs\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_003/'\n",
    "predict_with_name(X_test, model_path, target_imgs_lst, out_dir, input_shape, num_classes)\n",
    "\n",
    "del seped_zx_imgs, X_test, target_imgs, target_imgs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984037c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs, mito_imgs, masked_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_003/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_004/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_003/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "z_range = [int(ori_image_shape[0] * 0.1), int(ori_image_shape[0] * 0.9)]\n",
    "y_range = [int(ori_image_shape[1] * 0.1), int(ori_image_shape[1] * 0.9)]\n",
    "x_range = [int(ori_image_shape[2] * 0.1), int(ori_image_shape[2] * 0.9)]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for i in range(z_range[0], z_range[1]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.zeros(\n",
    "        (y_range[1] - y_range[0], x_range[1] - x_range[0], 1), np.float32\n",
    "    )\n",
    "    img_ = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )[y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(cnt).zfill(4)}.png', img_)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamellar_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_003/lamellar')\n",
    "tubular_imgs, _ = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_003/tubular')\n",
    "\n",
    "merged_imgs = lamellar_imgs * 255 + tubular_imgs * 255 * 2\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_003/merged_lamellar_and_tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for i in range(merged_imgs.shape[0]):\n",
    "    cv2.imwrite(\n",
    "        f\"{out_dir}/{str(i).zfill(4)}.png\",\n",
    "        merged_imgs[i]\n",
    "    )\n",
    "    \n",
    "    \n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/manually_cristae_003/'\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba831a",
   "metadata": {},
   "source": [
    "### pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f52713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_imgs , _ = load_X_gray('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/dataset/cropped_005/resize_10x10x10')\n",
    "\n",
    "ori_image_shape = ori_imgs.shape\n",
    "del ori_imgs\n",
    "\n",
    "ori_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_003/1')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_003/1')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_003/1')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_final/lamellar'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15605085",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_xy, imgs_xy_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_xy_003/2')\n",
    "\n",
    "full_imgs_xy_sheets = ori_image_shape[0] * (-(-ori_image_shape[1] // 412)) * (-(-ori_image_shape[2] // 412))\n",
    "full_imgs_xy = np.zeros((full_imgs_xy_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_xy, imgs_xy_filename):\n",
    "    full_imgs_xy[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_xy = merge_imgs(full_imgs_xy, ori_image_shape)\n",
    "\n",
    "del imgs_xy, full_imgs_xy\n",
    "\n",
    "\n",
    "imgs_yz, imgs_yz_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_yz_003/2')\n",
    "\n",
    "full_imgs_yz_sheets = ori_image_shape[2] * (-(-ori_image_shape[0] // 412)) * (-(-ori_image_shape[1] // 412))\n",
    "full_imgs_yz = np.zeros((full_imgs_yz_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_yz, imgs_yz_filename):\n",
    "    full_imgs_yz[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_yz = merge_imgs(full_imgs_yz, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "del imgs_yz, full_imgs_yz\n",
    "\n",
    "\n",
    "imgs_zx, imgs_zx_filename = load_Y_gray_with_gaussian('Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/cristae_pred_zx_003/2')\n",
    "\n",
    "full_imgs_zx_sheets = ori_image_shape[1] * (-(-ori_image_shape[2] // 412)) * (-(-ori_image_shape[0] // 412))\n",
    "full_imgs_zx = np.zeros((full_imgs_zx_sheets, 512, 512, 1), np.float32)\n",
    "for img, imgname in zip(imgs_zx, imgs_zx_filename):\n",
    "    full_imgs_zx[int(imgname.split(\".\")[0])] = img\n",
    "\n",
    "merged_imgs_zx = merge_imgs(full_imgs_zx, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))\n",
    "\n",
    "del imgs_zx, full_imgs_zx\n",
    "\n",
    "imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = 'Z:/DeepLearningData/research_010_NIH3T3/shOPA1_003/annotations/cropped_005/merged_cristae_final/tubular'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(cnt).zfill(4)}.png', img)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
